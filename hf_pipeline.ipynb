{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b870f8eb-4d05-4d91-ab20-e829c8011705",
   "metadata": {},
   "source": [
    "# Huggings Face - Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b43d52-bd01-4c84-903a-9c6cbed51348",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22095f06-1acd-4107-9b80-191621355b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895a1d15-7696-4cbb-a432-88188e2a242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d95e0e-28bc-4cc8-938e-ad850e1a1b2c",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb35c7ff-e351-4691-90c2-5ea9131dbf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English.\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0bad59-29a6-4c81-9737-2dcbb39a677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791ec0ef-6d45-4966-834f-a646d8c6caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f48399-eda3-44e0-87eb-f32d4ca5eaa3",
   "metadata": {},
   "source": [
    "## Zero-shot classification\n",
    "It allows you to specify which labels to use for the classification, so you don’t have to rely on the labels of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26986bc8-7195-4236-b71c-3b6dcc090164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "zeroshotclassifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae07790d-a5d1-4c85-ac1e-fa58a9015313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445988893508911, 0.11197422444820404, 0.04342690482735634]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshotclassifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fa9cb-9bb1-4535-bf27-f93904cec88a",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9a2c2c-6f5d-4c45-ad30-8816eadbdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92af9d0c096245f18e7088bf61de99e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047bb409712a4524b7af9793456845d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61087b6eaba46609177fa4597099636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4256491c08423a9a29e4760d40cd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13458be757e44282b84358ee50daf4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b627cc626455425fa243675b331f6b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447ca4b905264d8bad40047f3ad48622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b131f77-b349-4801-b521-68979701aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to work with your environment to solve problems on your own.\\n\\n\\nThis class is designed for business to help you understand how to work effectively with your environment.\\n\\n\\nWe will teach you to work effectively with the company as it goes about its business.\\n\\n\\nWe will teach you the fundamentals and what to expect of companies in regards to business.\\n\\n\\nWe will learn how to find and sell in a friendly environment.\\n\\n\\nWe will learn how'},\n",
       " {'generated_text': \"In this course, we will teach you how to create a beautiful web application from scratch, using Eclipse as a starting point. You'll understand how to easily start your projects and how to create an application using multiple browser plugins that can run concurrently, as well as how to build your application in Eclipse.\\n\\nPrerequisites\\n\\nThe only prerequisite to successfully make the application, is a Web browser. We will be using an old-school web browser called Chrome. We are going to build one and\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"In this course, we will teach you how to\", num_return_sequences=2, max_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06df9b3-83a0-411a-a5ed-c87c277b3415",
   "metadata": {},
   "source": [
    "## Select specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df554519-02d3-4e2f-bbf2-ca698b8a6093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170ff9ee10045c3b84b30370045b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2a52d78dd64c5686c510589928175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40a7e25b8744ea88e8f3b5290ed117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6d976dbfa147c49d89599c53c9ceef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eda2e40bc6f47f781f0b1d018d7e6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792c7999a3d6491eaa0a63dda1746af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4371d05614b45e78b1c835734de221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator_with_distilgpt2 = pipeline(\"text-generation\", model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a75d57-51fb-4fc6-a2b2-976eac88dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to control yourself when choosing a specific set of exercises for use in physical training.\\n\\n\\n\\n\\n'},\n",
       " {'generated_text': 'In this course, we will teach you how to generate your own video file using YouTube video or by using an iOS app in order to view video files'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_with_distilgpt2(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc8634-4430-4e21-bf52-f589af4a6e5c",
   "metadata": {},
   "source": [
    "## Mask filling\n",
    "The idea of this task is to fill in the blanks in a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22cfb4da-1b86-4960-a46f-04dd17923f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c643ea1e76d9426e8369041387f363b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee60f425b4f44188db679b405dfb402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d107a2490f492d876c3e3f68cf70fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb900a42210e4050941ca27decd2c399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3d0df2d79244339ab43daccedf2501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfb9d5de7084984a3c18361fce6b9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ba890a-8f00-43fd-9ec8-9ad247564e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19198444485664368,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04209214076399803,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3bb11e-2140-4ca8-aee8-19ca45e3282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.43303748965263367,\n",
       "   'token': 50118,\n",
       "   'token_str': '\\n',\n",
       "   'sequence': '<s>This product contains milk\\nchocolate<mask>fruit<mask>juice<mask>water<mask>sugar</s>'},\n",
       "  {'score': 0.14356417953968048,\n",
       "   'token': 73,\n",
       "   'token_str': '/',\n",
       "   'sequence': '<s>This product contains milk/chocolate<mask>fruit<mask>juice<mask>water<mask>sugar</s>'}],\n",
       " [{'score': 0.7519227266311646,\n",
       "   'token': 24410,\n",
       "   'token_str': ' grape',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate grapefruit<mask>juice<mask>water<mask>sugar</s>'},\n",
       "  {'score': 0.0906941294670105,\n",
       "   'token': 10267,\n",
       "   'token_str': ' jack',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate jackfruit<mask>juice<mask>water<mask>sugar</s>'}],\n",
       " [{'score': 0.24547459185123444,\n",
       "   'token': 73,\n",
       "   'token_str': '/',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit/juice<mask>water<mask>sugar</s>'},\n",
       "  {'score': 0.06125649809837341,\n",
       "   'token': 24410,\n",
       "   'token_str': ' grape',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit grapejuice<mask>water<mask>sugar</s>'}],\n",
       " [{'score': 0.10614870488643646,\n",
       "   'token': 73,\n",
       "   'token_str': '/',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit<mask>juice/water<mask>sugar</s>'},\n",
       "  {'score': 0.08526782691478729,\n",
       "   'token': 36098,\n",
       "   'token_str': ')/',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit<mask>juice)/water<mask>sugar</s>'}],\n",
       " [{'score': 0.2971690893173218,\n",
       "   'token': 12,\n",
       "   'token_str': '-',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit<mask>juice<mask>water-sugar</s>'},\n",
       "  {'score': 0.12241356074810028,\n",
       "   'token': 73,\n",
       "   'token_str': '/',\n",
       "   'sequence': '<s>This product contains milk<mask>chocolate<mask>fruit<mask>juice<mask>water/sugar</s>'}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"This product contains milk<mask>chocolate<mask>fruit<mask>juice<mask>water<mask>sugar\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a267b1-1bea-41dc-8de4-cb8833a1a802",
   "metadata": {},
   "source": [
    "## Named entity recognition\n",
    "The model has to find which parts of the input text correspond to entities such as persons, locations, or organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6f30c46-b5c8-4277-8057-ddd440b9e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e64bd3393794b6ea25c36078a6b7f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a7f80e89b457692c6949b7061f3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a3714dd614defa35dad5b4c4814d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc84373fdeb4150bc9c30955d4d9749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc061efb-4089-4ff4-9090-2c6a8db66814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c125fd-b89e-42f9-a0d1-da91cb392dda",
   "metadata": {},
   "source": [
    "## Question answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e137568-6aec-4738-9cf7-a415fd3f4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752f6d19694e4fa398fed3004dfec9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fec2c1df544cda9c741ee5385142d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcb4a7d82c64d0697480284a542b20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b5a9ca58674dacad954ee2cd439946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654f6479cdb545ecb6d0886a7cb1282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf241e6-3ab6-4994-b063-dd2ec56216da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949769854545593, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9430eb8-8ca8-40ed-96dc-78d5cc3aba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.43178874254226685,\n",
       " 'start': 1316,\n",
       " 'end': 1328,\n",
       " 'answer': 'seven towers'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"What is Lübeck known for?\",\n",
    "    context=\"The Hanseatic city of Lübeck (Low German: Lübęk, Lübeek; Latin: Lubeca; Polish: Liubice; adjective: lübsch, lübisch, lübeckisch) is an independent city in northern Germany. It is located in the south-east of Schleswig-Holstein on the Bay of Lübeck, a bay of the Baltic Sea. Lübeck is the second largest city in Schleswig-Holstein in terms of population after the state capital Kiel and the largest in terms of area. The Hanseatic city on the Trave is one of the state's four regional centers, with a port, a specialized university with a hospital, a technical university and a music academy. The Lübeck Theater, the Music and Congress Hall and fifteen museums offer a rich cultural offering. Lübeck was founded in 1143 at its present location and was a city-state from 1226 to 1937. As the capital of the Hanseatic League, Lübeck was one of the most important cities in Northern Europe in the 13th and 14th centuries. The preserved areas of Lübeck's old town with over a thousand cultural monuments have been a UNESCO World Heritage Site since 1987. These include some important buildings of medieval brick architecture, such as St. Mary's Church in Lübeck, the town hall, one of the oldest cathedrals on the Baltic Sea, the Holy Ghost Hospital, the Holsten Gate and the castle gate. The city is also famous for its seven towers and Lübeck marzipan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94098862-4240-422e-aadf-a97939b038c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8702612519264221,\n",
       " 'start': 1333,\n",
       " 'end': 1348,\n",
       " 'answer': 'Lübeck marzipan'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"Which food is fames in Lübeck?\",\n",
    "    context=\"The Hanseatic city of Lübeck (Low German: Lübęk, Lübeek; Latin: Lubeca; Polish: Liubice; adjective: lübsch, lübisch, lübeckisch) is an independent city in northern Germany. It is located in the south-east of Schleswig-Holstein on the Bay of Lübeck, a bay of the Baltic Sea. Lübeck is the second largest city in Schleswig-Holstein in terms of population after the state capital Kiel and the largest in terms of area. The Hanseatic city on the Trave is one of the state's four regional centers, with a port, a specialized university with a hospital, a technical university and a music academy. The Lübeck Theater, the Music and Congress Hall and fifteen museums offer a rich cultural offering. Lübeck was founded in 1143 at its present location and was a city-state from 1226 to 1937. As the capital of the Hanseatic League, Lübeck was one of the most important cities in Northern Europe in the 13th and 14th centuries. The preserved areas of Lübeck's old town with over a thousand cultural monuments have been a UNESCO World Heritage Site since 1987. These include some important buildings of medieval brick architecture, such as St. Mary's Church in Lübeck, the town hall, one of the oldest cathedrals on the Baltic Sea, the Holy Ghost Hospital, the Holsten Gate and the castle gate. The city is also famous for its seven towers and Lübeck marzipan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22787de-60f2-4c44-af85-8fa7bbaa5652",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78763cae-21e7-4839-8c0a-e2503e670850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73c4b0455b0474ea2ceeabbd61ba5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d801d9323b8e4dba9cd925b7093c7dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531c3fbe977a47cc82fdf4ae8e640369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefd2a3ad5ae478ca5ca4b71d6e19698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a5bd55bbe24eb48ff35a3b46145b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a20bcabc-8bd4-43e6-8f02-ec315c7436d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' A report about a brutal St. Nicholas custom on the island of Borkum caused outrage across Germany . The police announced that there would be no more violence at the “Klaasohm” festival . Police encouraged women who have experienced violence during the custom to press charges .'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"Costumed men beat women with cow horns: this brutal custom, the “Klaasohm” festival, has a long tradition on Borkum. Following a Panorama report, there is great outrage - and the organizers are taking action.After a report about a brutal St. Nicholas custom on the North Sea island of Borkum, the organizers and the police have announced consequences. The police announced that there would be no more violence at the “Klaasohm” festival. The event will be accompanied by numerous police officers. “We have a zero-tolerance policy,” said a police spokesperson, and the police encouraged women who have experienced violence during the custom to press charges. “Anyone who has been a victim should not be afraid,” emphasized the police spokesperson. Offenses such as assault or grievous bodily harm are only time-barred after 20 to 30 years. Beatings with cow hornsThe “Klaasohm” festival on the evening of December 5 has a long tradition on Borkum. Part of the festival is a procession in which women are caught and beaten with cow horns by costumed men, the “Klaasohms”, after a report on the tradition by the ARD magazine Panorama caused outrage across Germany. \", max_length=100, min_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f7a1f-f8b5-4a11-a20b-184f7352795f",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90ebe692-4888-4cba-a704-7dfd5199a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93c691a4-55ca-4549-998e-326153747af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
